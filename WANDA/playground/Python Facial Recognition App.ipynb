{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244371d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf42d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb22e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 19:26:04.167871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Insert tensorflow dependencies - functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a017dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set GPU Growth\n",
    "gpus  = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66045568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder Structure\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANG_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06904c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(POS_PATH)\n",
    "#os.makedirs(NEG_PATH)\n",
    "#os.makedirs(ANG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfde41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://vis-www.cs.umass.edu/Lfw/\n",
    "#Uncompress LFW.Tar FILE\n",
    "#!tar -xf lfw.tar\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cda036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move LFW IMAGES to NEG_PATH\n",
    "#for directory in os.listdir('lfw'):\n",
    "#    for file in os.listdir(os.path.join('lfw',directory)):\n",
    "#        EX_PATH = os.path.join('lfw', directory, file)\n",
    "#        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "#        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab50f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Positive and Anchor classes\n",
    "#__Webcam Connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    break\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Adjust frame size\n",
    "    frame = frame[150:150+250, 200:200+250, :]\n",
    "    \n",
    "    #Collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        imgname = os.path.join(ANG_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    #Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    #Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    #Break\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343d6451",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: data/anchor\\\\*.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Get Image Directories\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m anchor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mANG_PATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m*.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m positive \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(POS_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      4\u001b[0m negative \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(NEG_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:1289\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1282\u001b[0m condition \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mgreater(array_ops\u001b[38;5;241m.\u001b[39mshape(matching_files)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   1283\u001b[0m                              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1285\u001b[0m message \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files matched pattern: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1287\u001b[0m     string_ops\u001b[38;5;241m.\u001b[39mreduce_join(file_pattern, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1289\u001b[0m assert_not_empty \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massert_not_empty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[1;32m   1292\u001b[0m   matching_files \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39midentity(matching_files)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/control_flow_ops.py:156\u001b[0m, in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m     xs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[1;32m    155\u001b[0m     data_str \u001b[38;5;241m=\u001b[39m [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[1;32m    157\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    160\u001b[0m         (condition, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_str)))\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssert\u001b[39m\u001b[38;5;124m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: data/anchor\\\\*.jpg'"
     ]
    }
   ],
   "source": [
    "#Get Image Directories\n",
    "anchor = tf.data.Dataset.list_files(ANG_PATH + '\\*.jpg').take(20)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH + '\\*.jpg').take(20)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH + '\\*.jpg').take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = achor.as_numpy_iterator()\n",
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.read_file(byte_img)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0272ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labelled Dataset\n",
    "positives = tf.data.Dataset.zip(acnhor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor))))\n",
    "negatives = tf.data.Dataset.zip(acnhor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73baa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0504e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
